{
	"name": "Tutorial - Cognitive Service",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "sparkpool01",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "5ad45370-f8b3-463c-b570-7e129c33e907"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/3c3bb71f-3a4c-436f-9e0a-7407d75a82fa/resourceGroups/2022-DSI-Resources/providers/Microsoft.Synapse/workspaces/2022-dsi-synapse-ws/bigDataPools/sparkpool01",
				"name": "sparkpool01",
				"type": "Spark",
				"endpoint": "https://2022-dsi-synapse-ws.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool01",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Tutorial: Build intelligent applications using Azure Cognitive Services in Microsoft Machine Learning for Apache Spark\r\n",
					"\r\n",
					"In this article, you will learn how to use Microsoft Machine Learning for Apache Spark ([MMLSpark](https://github.com/Azure/mmlspark)) to create machine learning applications. \r\n",
					"MMLSpark expands the distributed machine learning solution of Apache Spark by adding many deep learning and data science tools, such as [Azure Cognitive Services](../../cognitive-services/big-data/cognitive-services-for-big-data.md), [OpenCV](https://opencv.org/), [LightGBM](https://github.com/Microsoft/LightGBM) and more.  MMLSpark allows you to build powerful and highly scalable predictive and analytical models from various Spark data sources.\r\n",
					"Synapse Spark provide built-in MMLSpark libraries including:\r\n",
					"\r\n",
					"- [Vowpal Wabbit](https://github.com/Azure/mmlspark/blob/master/docs/vw.md) – Library services for Machine learning to enable Text analytics like sentiment analysis in tweets.\r\n",
					"- [Cognitive Services on Spark](https://github.com/Azure/mmlspark/blob/master/docs/cogsvc.md) – To combine the feature of Azure Cognitive Services in SparkML pipelines in order to derive solution design for cognitive data modeling services like anomaly detection.\r\n",
					"- [LightGBM](https://github.com/Azure/mmlspark/blob/master/docs/lightgbm.md) – LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and higher efficiency.\r\n",
					"- Conditional KNN - Scalable KNN Models with Conditional Queries.\r\n",
					"- [HTTP on Spark](https://github.com/Azure/mmlspark/blob/master/docs/http.md) – Enables distributed Microservices orchestration in integrating Spark and HTTP protocol-based accessibility.\r\n",
					"\r\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"<img width=\"200\"  src=\"https://mmlspark.blob.core.windows.net/graphics/Readme/cog_services_on_spark_2.svg\">\r\n",
					"\r\n",
					"This tutorial covers samples using [Azure Cognitive Services](https://azure.microsoft.com/services/cognitive-services/) in MMLSpark for \r\n",
					"\r\n",
					"- Text Analytics - get the sentiment (or mood) of a set of sentences.\r\n",
					"- Computer Vision - get the tags (one-word descriptions) associated with a set of images.\r\n",
					"- Bing Image Search - search the web for images related to a natural language query.\r\n",
					"- Anomaly Detector - detect anomalies within a time series data.\r\n",
					"- Speech to Text - convert streams or files of spoken audio to text.\r\n",
					"\r\n",
					"If you don't have an Azure subscription, [create a free account before you begin](https://azure.microsoft.com/free/).\r\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Prerequisites \r\n",
					"\r\n",
					"- [Azure Synapse Analytics workspace](https://docs.microsoft.com/azure/synapse-analytics/get-started-create-workspace) with an Azure Data Lake Storage Gen2 storage account configured as the default storage. You need to be the *Storage Blob Data Contributor* of the Data Lake Storage Gen2 file system that you work with.\r\n",
					"- Spark pool in your Azure Synapse Analytics workspace. For details, see [Create a Spark pool in Azure Synapse](https://docs.microsoft.com/azure/synapse-analytics/get-started-analyze-spark).\r\n",
					"- Pre-configuration steps described in the tutorial [Configure Cognitive Services in Azure Synapse](https://docs.microsoft.com/azure/synapse-analytics/machine-learning/tutorial-configure-cognitive-services-synapse)."
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Get started\r\n",
					"To get started, import mmlspark and configurate service keys. "
				]
			},
			{
				"cell_type": "code",
				"source": [
					"import mmlspark\r\n",
					"mmlspark.__spark_package_version__ # current version: 1.0.0-rc3-6-a862d6b1-SNAPSHOT\r\n",
					"\r\n",
					"from mmlspark.cognitive import *\r\n",
					"from notebookutils import mssparkutils\r\n",
					"\r\n",
					"# A general Cognitive Services key for Text Analytics and Computer Vision (or use separate keys that belong to each service)\r\n",
					"cognitive_service_key = mssparkutils.credentials.getSecret(\"ADD_YOUR_KEY_VAULT_NAME\", \"ADD_YOUR_SERVICE_KEY\",\"ADD_YOUR_KEY_VAULT_LINKED_SERVICE_NAME\") \r\n",
					"# A Bing Search v7 subscription key\r\n",
					"bingsearch_service_key = mssparkutils.credentials.getSecret(\"ADD_YOUR_KEY_VAULT_NAME\", \"ADD_YOUR_BING_SEARCH_KEY\",\"ADD_YOUR_KEY_VAULT_LINKED_SERVICE_NAME\")\r\n",
					"# An Anomaly Dectector subscription key\r\n",
					"anomalydetector_key = mssparkutils.credentials.getSecret(\"ADD_YOUR_KEY_VAULT_NAME\", \"ADD_YOUR_ANOMALY_KEY\",\"ADD_YOUR_KEY_VAULT_LINKED_SERVICE_NAME\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Text analytics sample\r\n",
					"\r\n",
					"The [Text Analytics](https://docs.microsoft.com/azure/cognitive-services/text-analytics/) service provides several algorithms for extracting intelligent insights from text. For example, we can find the sentiment of given input text. The service will return a score between 0.0 and 1.0 where low scores indicate negative sentiment and high score indicates positive sentiment. This sample uses three simple sentences and returns the sentiment for each.\r\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"from pyspark.sql.functions import col\r\n",
					"\r\n",
					"# Create a dataframe that's tied to it's column names\r\n",
					"df_sentences = spark.createDataFrame([\r\n",
					"  (\"I am so happy today, its sunny!\", \"en-US\"), \r\n",
					"  (\"this is a dog\", \"en-US\"), \r\n",
					"  (\"I am frustrated by this rush hour traffic!\", \"en-US\") \r\n",
					"], [\"text\", \"language\"])\r\n",
					"\r\n",
					"# Run the Text Analytics service with options\r\n",
					"sentiment = (TextSentiment()\r\n",
					"    .setTextCol(\"text\")\r\n",
					"    .setLocation(\"eastasia\") # Set the location of your cognitive service\r\n",
					"    .setSubscriptionKey(cognitive_service_key)\r\n",
					"    .setOutputCol(\"sentiment\")\r\n",
					"    .setErrorCol(\"error\")\r\n",
					"    .setLanguageCol(\"language\"))\r\n",
					"\r\n",
					"# Show the results of your text query in a table format\r\n",
					"\r\n",
					"display(sentiment.transform(df_sentences).select(\"text\", col(\"sentiment\")[0].getItem(\"sentiment\").alias(\"sentiment\")))"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Expected results\r\n",
					"\r\n",
					"|text | sentiment|\r\n",
					"|--|--|\r\n",
					"| I am frustrated by this rush hour traffic! | negative |\r\n",
					"| this is a dog | neutral |\r\n",
					"| I am so happy today, its sunny! | positive |\r\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Computer vision sample\r\n",
					"[Computer Vision](https://docs.microsoft.com/azure/cognitive-services/computer-vision/) analyzes images to identify structure such as faces, objects, and natural-language descriptions. In this sample, we tag the follow image. Tags are one-word descriptions of things in the image like recognizable objects, people, scenery, and actions.\r\n",
					"\r\n",
					"\r\n",
					"![image](https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg)\r\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"# Create a dataframe with the image URL\r\n",
					"df_images = spark.createDataFrame([\r\n",
					"        (\"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\", )\r\n",
					"    ], [\"image\", ])\r\n",
					"\r\n",
					"# Run the Computer Vision service. Analyze Image extracts information from/about the images.\r\n",
					"analysis = (AnalyzeImage()\r\n",
					"    .setLocation(\"eastasia\") # Set the location of your cognitive service\r\n",
					"    .setSubscriptionKey(cognitive_service_key)\r\n",
					"    .setVisualFeatures([\"Categories\",\"Color\",\"Description\",\"Faces\",\"Objects\",\"Tags\"])\r\n",
					"    .setOutputCol(\"analysis_results\")\r\n",
					"    .setImageUrlCol(\"image\")\r\n",
					"    .setErrorCol(\"error\"))\r\n",
					"\r\n",
					"# Show the results of what you wanted to pull out of the images.\r\n",
					"display(analysis.transform(df_images).select(\"image\", \"analysis_results.description.tags\"))"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Expected results\r\n",
					"\r\n",
					"|image | tags|\r\n",
					"|--|--|\r\n",
					"| `https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg` | [skating, person, man, outdoor, riding, sport, skateboard, young, board, shirt, air, park, boy, side, jumping, ramp, trick, doing, flying] |\r\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Bing image search sample\r\n",
					"[Bing Image Search](https://docs.microsoft.com/azure/cognitive-services/bing-image-search/overview) searches the web to retrieve images related to a user's natural language query. In this sample, we use a text query that looks for images with quotes. It returns a list of image URLs that contain photos related to our query.\r\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"from pyspark.ml import PipelineModel\n",
					"\n",
					"# Number of images Bing will return per query\n",
					"imgsPerBatch = 2\n",
					"# A list of offsets, used to page into the search results\n",
					"offsets = [(i*imgsPerBatch,) for i in range(10)]\n",
					"# Since web content is our data, we create a dataframe with options on that data: offsets\n",
					"bingParameters = spark.createDataFrame(offsets, [\"offset\"])\n",
					"\n",
					"# Run the Bing Image Search service with our text query\n",
					"bingSearch = (BingImageSearch()\n",
					"    .setSubscriptionKey(bingsearch_service_key)\n",
					"    .setOffsetCol(\"offset\")\n",
					"    .setQuery(\"Martin Luther King Jr. quotes\")\n",
					"    .setCount(imgsPerBatch)\n",
					"    .setUrl(\"https://api.bing.microsoft.com/v7.0/images/search\")\n",
					"    .setOutputCol(\"images\"))\n",
					"\n",
					"# Transformer that extracts and flattens the richly structured output of Bing Image Search into a simple URL column\n",
					"getUrls = BingImageSearch.getUrlTransformer(\"images\", \"url\")\n",
					"pipeline_bingsearch = PipelineModel(stages=[bingSearch, getUrls])\n",
					"\n",
					"# Show the results of your search: image URLs\n",
					"res_bingsearch = pipeline_bingsearch.transform(bingParameters)\n",
					"display(res_bingsearch.dropDuplicates())"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Expected results\r\n",
					"\r\n",
					"|image | \r\n",
					"|--|\r\n",
					"|`http://everydaypowerblog.com/wp-content/uploads/2014/01/Martin-Luther-King-Jr.-Quotes-16.jpg` |\r\n",
					"|`http://www.scrolldroll.com/wp-content/uploads/2017/06/6-25.png` |\r\n",
					"| `http://abettertodaymedia.com/wp-content/uploads/2017/01/86783bd7a92960aedd058c91a1d10253.jpg`|\r\n",
					"| `https://weneedfun.com/wp-content/uploads/2016/05/martin-luther-king-jr-quotes-11.jpg` |\r\n",
					"| `http://www.sofreshandsogreen.com/wp-content/uploads/2012/01/martin-luther-king-jr-quote-sofreshandsogreendotcom.jpg` |\r\n",
					"| `https://cdn.quotesgram.com/img/72/57/1104209728-martin_luther_king_jr_quotes_16.jpg` |\r\n",
					"| `http://comicbookandbeyond.com/wp-content/uploads/2019/05/Martin-Luther-King-Jr.-Quotes.jpg` |\r\n",
					"| `https://exposingthepain.files.wordpress.com/2015/01/martin-luther-king-jr-quotes-08.png` |\r\n",
					"| `https://topmemes.me/wp-content/uploads/2020/01/Top-10-Martin-Luther-King-jr.-Quotes2-1024x538.jpg` |\r\n",
					"| `http://img.picturequotes.com/2/581/580286/dr-martin-luther-king-jr-quote-1-picture-quote-1.jpg` |\r\n",
					"| `http://parryz.com/wp-content/uploads/2017/06/Amazing-Martin-Luther-King-Jr-Quotes.jpg` |\r\n",
					"| `http://everydaypowerblog.com/wp-content/uploads/2014/01/Martin-Luther-King-Jr.-Quotes1.jpg` |\r\n",
					"| `https://lessonslearnedinlife.net/wp-content/uploads/2020/05/Martin-Luther-King-Jr.-Quotes-2020.jpg` |\r\n",
					"| `https://quotesblog.net/wp-content/uploads/2015/10/Martin-Luther-King-Jr-Quotes-Wallpaper.jpg` |\r\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Anomaly detector sample\r\n",
					"\r\n",
					"[Anomaly Detector](https://docs.microsoft.com/en-us/azure/cognitive-services/anomaly-detector/) is great for detecting irregularities in your time series data. In this sample, we use the service to find anomalies in the entire time series."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"from pyspark.sql.functions import lit\r\n",
					"\r\n",
					"# Create a dataframe with the point data that Anomaly Detector requires\r\n",
					"df_timeseriesdata = spark.createDataFrame([\r\n",
					"    (\"1972-01-01T00:00:00Z\", 826.0),\r\n",
					"    (\"1972-02-01T00:00:00Z\", 799.0),\r\n",
					"    (\"1972-03-01T00:00:00Z\", 890.0),\r\n",
					"    (\"1972-04-01T00:00:00Z\", 900.0),\r\n",
					"    (\"1972-05-01T00:00:00Z\", 766.0),\r\n",
					"    (\"1972-06-01T00:00:00Z\", 805.0),\r\n",
					"    (\"1972-07-01T00:00:00Z\", 821.0),\r\n",
					"    (\"1972-08-01T00:00:00Z\", 20000.0), # anomaly\r\n",
					"    (\"1972-09-01T00:00:00Z\", 883.0),\r\n",
					"    (\"1972-10-01T00:00:00Z\", 898.0),\r\n",
					"    (\"1972-11-01T00:00:00Z\", 957.0),\r\n",
					"    (\"1972-12-01T00:00:00Z\", 924.0),\r\n",
					"    (\"1973-01-01T00:00:00Z\", 881.0),\r\n",
					"    (\"1973-02-01T00:00:00Z\", 837.0),\r\n",
					"    (\"1973-03-01T00:00:00Z\", 9000.0) # anomaly\r\n",
					"], [\"timestamp\", \"value\"]).withColumn(\"group\", lit(\"series1\"))\r\n",
					"\r\n",
					"# Run the Anomaly Detector service to look for irregular data\r\n",
					"anamoly_detector = (SimpleDetectAnomalies()\r\n",
					"  .setSubscriptionKey(anomalydetector_key)\r\n",
					"  .setLocation(\"eastasia\")  # Set the location of your Anomaly Detector service service\r\n",
					"  .setTimestampCol(\"timestamp\")\r\n",
					"  .setValueCol(\"value\")\r\n",
					"  .setOutputCol(\"anomalies\")\r\n",
					"  .setGroupbyCol(\"group\")\r\n",
					"  .setGranularity(\"monthly\"))\r\n",
					"\r\n",
					"# Show the full results of the analysis with the anomalies marked as \"True\"\r\n",
					"display(anamoly_detector.transform(df_timeseriesdata).select(\"timestamp\", \"value\", \"anomalies.isAnomaly\"))"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Expected results\r\n",
					"\r\n",
					"|timestamp | value | isAnomaly |\r\n",
					"|--|--|--|\r\n",
					"| 1972-01-01T00:00:00Z|826.0|false|\r\n",
					"|1972-02-01T00:00:00Z|799.0|false|\r\n",
					"|1972-03-01T00:00:00Z|890.0|false|\r\n",
					"|1972-04-01T00:00:00Z|900.0|false|\r\n",
					"|1972-05-01T00:00:00Z|766.0|false|\r\n",
					"|1972-06-01T00:00:00Z|805.0|false|\r\n",
					"|1972-07-01T00:00:00Z|821.0|false|\r\n",
					"|1972-08-01T00:00:00Z|20000.0|true|\r\n",
					"|1972-09-01T00:00:00Z|883.0|false|\r\n",
					"|1972-10-01T00:00:00Z|898.0|false|\r\n",
					"|1972-11-01T00:00:00Z|957.0|false|\r\n",
					"|1972-12-01T00:00:00Z|924.0|false|\r\n",
					"|1973-01-01T00:00:00Z|881.0|false|\r\n",
					"|1973-02-01T00:00:00Z|837.0|false|\r\n",
					"|1973-03-01T00:00:00Z|9000.0|true|"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Speech-to-Text sample\r\n",
					"\r\n",
					"The [Speech-to-text](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-speech-to-text) service converts streams or files of spoken audio to text. In this sample, we transcribe one audio file to text. "
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"# Create a dataframe with our audio URLs, tied to the column called \"url\"\n",
					"df = spark.createDataFrame([(\"https://mmlspark.blob.core.windows.net/datasets/Speech/audio2.wav\",)\n",
					"                           ], [\"url\"])\n",
					"\n",
					"# Run the Speech-to-text service to translate the audio into text\n",
					"speech_to_text = (SpeechToTextSDK()\n",
					"    .setSubscriptionKey(cognitive_service_key)\n",
					"    .setLocation(\"northeurope\") # Set the location of your cognitive service\n",
					"    .setOutputCol(\"text\")\n",
					"    .setAudioDataCol(\"url\")\n",
					"    .setLanguage(\"en-US\")\n",
					"    .setProfanity(\"Masked\"))\n",
					"\n",
					"# Show the results of the translation\n",
					"display(speech_to_text.transform(df).select(\"url\", \"text.DisplayText\"))"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Expected results\r\n",
					"\r\n",
					"|url | DisplayText |\r\n",
					"|--|--|\r\n",
					"| `https://mmlspark.blob.core.windows.net/datasets/Speech/audio2.wav` | Custom Speech provides tools that allow you to visually inspect the recognition quality of a model by comparing audio data with the corresponding recognition result from the custom speech portal. You can playback uploaded audio and determine if the provided recognition result is correct. This tool allows you to quickly inspect quality of Microsoft's baseline speech to text model or a trained custom model without having to transcribe any audio data.|\r\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Clean up resources\r\n",
					"To ensure the Spark instance is shut down, end any connected sessions(notebooks). The pool shuts down when the **idle time** specified in the Apache Spark pool is reached. You can also select **stop session** from the status bar at the upper right of the notebook.\r\n",
					"\r\n",
					"![stopsession](https://adsnotebookrelease.blob.core.windows.net/adsnotebookrelease/adsnotebook/image/stopsession.png)"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Next steps\r\n",
					"\r\n",
					"* [Check out Synapse sample notebooks](https://github.com/Azure-Samples/Synapse/tree/main/MachineLearning) \r\n",
					"* [MMLSpark GitHub Repo](https://github.com/Azure/mmlspark)\r\n",
					""
				]
			}
		]
	}
}