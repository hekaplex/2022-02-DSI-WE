{
	"name": "ML_ONNX_Demo",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "sparkpoolminko",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "56g",
			"driverCores": 8,
			"executorMemory": "56g",
			"executorCores": 8,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "07ccf3cb-9ba0-45da-a892-a72d2295a5d1"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/108eca19-ac11-46cc-ac0b-5931364e4e4c/resourceGroups/minko/providers/Microsoft.Synapse/workspaces/hekaplex-synapse/bigDataPools/sparkpoolminko",
				"name": "sparkpoolminko",
				"type": "Spark",
				"endpoint": "https://hekaplex-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpoolminko",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 3,
				"cores": 8,
				"memory": 56,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"import numpy as np\r\n",
					"import onnxmltools\r\n",
					"import onnxruntime as rt\r\n",
					"import pandas as pd\r\n",
					"import skl2onnx\r\n",
					"import sklearn\r\n",
					"import sklearn.datasets\r\n",
					"\r\n",
					"from sklearn.datasets import load_boston\r\n",
					"boston = load_boston()\r\n",
					"boston\r\n",
					"\r\n",
					"df = pd.DataFrame(data=np.c_[boston['data'], boston['target']], columns=boston['feature_names'].tolist() + ['MEDV'])\r\n",
					" \r\n",
					"target_column = 'MEDV'\r\n",
					" \r\n",
					"# Split the data frame into features and target\r\n",
					"x_train = pd.DataFrame(df.drop([target_column], axis = 1))\r\n",
					"y_train = pd.DataFrame(df.iloc[:,df.columns.tolist().index(target_column)])\r\n",
					"\r\n",
					"print(\"\\n*** Training dataset x\\n\")\r\n",
					"print(x_train.head())\r\n",
					"\r\n",
					"print(\"\\n*** Training dataset y\\n\")\r\n",
					"print(y_train.head())"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from sklearn.compose import ColumnTransformer\r\n",
					"from sklearn.linear_model import LinearRegression\r\n",
					"from sklearn.pipeline import Pipeline\r\n",
					"from sklearn.preprocessing import RobustScaler\r\n",
					"\r\n",
					"continuous_transformer = Pipeline(steps=[('Scaler', RobustScaler())])\r\n",
					"\r\n",
					"# All columns are numeric - normalize them\r\n",
					"preprocessor = ColumnTransformer(\r\n",
					"    transformers=[\r\n",
					"        ('continuous', continuous_transformer, [i for i in range(len(x_train.columns))])])\r\n",
					"\r\n",
					"model = Pipeline(\r\n",
					"    steps=[\r\n",
					"        ('preprocessor', preprocessor),\r\n",
					"        ('regressor', LinearRegression())])\r\n",
					"\r\n",
					"# Train the model\r\n",
					"model.fit(x_train, y_train)"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Score the model\r\n",
					"from sklearn.metrics import r2_score, mean_squared_error\r\n",
					"y_pred = model.predict(x_train)\r\n",
					"sklearn_r2_score = r2_score(y_train, y_pred)\r\n",
					"sklearn_mse = mean_squared_error(y_train, y_pred)\r\n",
					"print('*** Scikit-learn r2 score: {}'.format(sklearn_r2_score))\r\n",
					"print('*** Scikit-learn MSE: {}'.format(sklearn_mse))"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from skl2onnx.common.data_types import FloatTensorType, Int64TensorType, DoubleTensorType\r\n",
					"\r\n",
					"def convert_dataframe_schema(df, drop=None, batch_axis=False):\r\n",
					"    inputs = []\r\n",
					"    nrows = None if batch_axis else 1\r\n",
					"    for k, v in zip(df.columns, df.dtypes):\r\n",
					"        if drop is not None and k in drop:\r\n",
					"            continue\r\n",
					"        if v == 'int64':\r\n",
					"            t = Int64TensorType([nrows, 1])\r\n",
					"        elif v == 'float32':\r\n",
					"            t = FloatTensorType([nrows, 1])\r\n",
					"        elif v == 'float64':\r\n",
					"            t = DoubleTensorType([nrows, 1])\r\n",
					"        else:\r\n",
					"            raise Exception(\"Bad type\")\r\n",
					"        inputs.append((k, t))\r\n",
					"    return inputs"
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Convert the scikit model to onnx format\r\n",
					"onnx_model = skl2onnx.convert_sklearn(model, 'Boston Data', convert_dataframe_schema(x_train), final_types=[('variable1',FloatTensorType([1,1]))])\r\n",
					"# Save the onnx model locally\r\n",
					"onnx_model_path = 'boston1.model.onnx'\r\n",
					"onnxmltools.utils.save_model(onnx_model, onnx_model_path)"
				],
				"execution_count": 14
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import onnxruntime as rt\r\n",
					"sess = rt.InferenceSession(onnx_model_path)\r\n",
					"\r\n",
					"y_pred = np.full(shape=(len(x_train)), fill_value=np.nan)\r\n",
					"\r\n",
					"for i in range(len(x_train)):\r\n",
					"    inputs = {}\r\n",
					"    for j in range(len(x_train.columns)):\r\n",
					"        inputs[x_train.columns[j]] = np.full(shape=(1,1), fill_value=x_train.iloc[i,j])\r\n",
					"\r\n",
					"    sess_pred = sess.run(None, inputs)\r\n",
					"    y_pred[i] = sess_pred[0][0][0]\r\n",
					"\r\n",
					"onnx_r2_score = r2_score(y_train, y_pred)\r\n",
					"onnx_mse = mean_squared_error(y_train, y_pred)\r\n",
					"\r\n",
					"print()\r\n",
					"print('*** Onnx r2 score: {}'.format(onnx_r2_score))\r\n",
					"print('*** Onnx MSE: {}\\n'.format(onnx_mse))\r\n",
					"print('R2 Scores are equal' if sklearn_r2_score == onnx_r2_score else 'Difference in R2 scores: {}'.format(abs(sklearn_r2_score - onnx_r2_score)))\r\n",
					"print('MSE are equal' if sklearn_mse == onnx_mse else 'Difference in MSE scores: {}'.format(abs(sklearn_mse - onnx_mse)))\r\n",
					"print()"
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					""
				],
				"execution_count": null
			}
		]
	}
}